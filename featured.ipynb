{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "163a852e",
   "metadata": {},
   "source": [
    "# 학생들의 기본 피쳐만 가지고 상관관계 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7deea36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 로드\n",
    "df = pd.read_csv('./data/studentInfo.csv')\n",
    "\n",
    "# 안쓰는 컬럼 삭제\n",
    "df = df.drop(['code_module', 'code_presentation', 'num_of_prev_attempts', 'studied_credits'], axis=1)\n",
    "\n",
    "# 모든 컬럼이 같은 행을 삭제\n",
    "df = df.drop_duplicates(subset=df.columns.difference(['final_result']), keep='first').reset_index(drop=True)\n",
    "df.duplicated(subset=df.columns.difference(['final_result'])).sum()\n",
    "\n",
    "# withdrawn이면 1, 아니면 0 인 dropout_status 컬럼 생성\n",
    "df['dropout_status'] = np.where(df['final_result'] == 'Withdrawn', 1, 0)\n",
    "df = df.drop(['final_result'], axis=1)\n",
    "df = df.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "df.duplicated().sum()\n",
    "\n",
    "# 중복 행 제거\n",
    "ids_with_both = df.groupby('id_student')['dropout_status'].nunique()\n",
    "ids_with_both = ids_with_both[ids_with_both > 1].index\n",
    "df = df[~df['id_student'].isin(ids_with_both)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20c690e",
   "metadata": {},
   "source": [
    "### 데이터 전처리 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24f27e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(data):\n",
    "    # ----- 매핑 딕셔너리 -----\n",
    "    gender_map = {'F': 0, 'M': 1}\n",
    "    disability_map = {'N': 0, 'Y': 1}\n",
    "    age_band_map = {'0-35': 0, '35-55': 1, '55<=': 2}\n",
    "    he_map = {\n",
    "        'No Formal quals': 0,\n",
    "        'Lower Than A Level': 1,\n",
    "        'A Level or Equivalent': 2,\n",
    "        'HE Qualification': 3,\n",
    "        'Post Graduate Qualification': 4\n",
    "    }\n",
    "    imd_map = {\n",
    "        '0-10%': 1, '10-20': 2, '20-30%': 3, '30-40%': 4, '40-50%': 5,\n",
    "        '50-60%': 6, '60-70%': 7, '70-80%': 8, '80-90%': 9, '90-100%': 10\n",
    "    }\n",
    "    region_map = {\n",
    "        'East Anglian Region': 0,\n",
    "        'East Midlands Region': 1,\n",
    "        'Ireland': 2,\n",
    "        'London Region': 3,\n",
    "        'North Region': 4,\n",
    "        'North Western Region': 5,\n",
    "        'Scotland': 6,\n",
    "        'South East Region': 7,\n",
    "        'South Region': 8,\n",
    "        'South West Region': 9,\n",
    "        'Wales': 10,\n",
    "        'West Midlands Region': 11,\n",
    "        'Yorkshire Region': 12\n",
    "    }\n",
    "\n",
    "    # ----- 2) 라벨 인코딩 -----\n",
    "    data['gender'] = data['gender'].map(gender_map)\n",
    "    data['disability'] = data['disability'].map(disability_map)\n",
    "    data['age_band'] = data['age_band'].map(age_band_map)\n",
    "    data['highest_education'] = data['highest_education'].map(he_map)\n",
    "\n",
    "    data['imd_band'] = data['imd_band'].replace('?', pd.NA).map(imd_map)\n",
    "    data = data.dropna(subset=['imd_band'])  # '?'가 있던 행 제거\n",
    "\n",
    "    data['region'] = data['region'].map(region_map)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4259755c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_2584\\848437386.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['region'] = data['region'].map(region_map)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 수행\n",
    "df = preprocess_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "428d0994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_student</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>highest_education</th>\n",
       "      <th>imd_band</th>\n",
       "      <th>age_band</th>\n",
       "      <th>disability</th>\n",
       "      <th>dropout_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11391</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28400</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30268</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31604</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32885</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27746</th>\n",
       "      <td>2640965</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27747</th>\n",
       "      <td>2645731</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27748</th>\n",
       "      <td>2648187</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27749</th>\n",
       "      <td>2679821</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27750</th>\n",
       "      <td>2684003</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27751 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_student  gender  region  highest_education  imd_band  age_band  \\\n",
       "0           11391       1       0                  3      10.0         2   \n",
       "1           28400       0       6                  3       3.0         1   \n",
       "2           30268       0       5                  2       4.0         1   \n",
       "3           31604       0       7                  2       6.0         1   \n",
       "4           32885       0      11                  1       6.0         0   \n",
       "...           ...     ...     ...                ...       ...       ...   \n",
       "27746     2640965       0      10                  1       2.0         0   \n",
       "27747     2645731       0       0                  1       5.0         1   \n",
       "27748     2648187       0       8                  2       3.0         0   \n",
       "27749     2679821       0       7                  1      10.0         1   \n",
       "27750     2684003       0      12                  3       6.0         1   \n",
       "\n",
       "       disability  dropout_status  \n",
       "0               0               0  \n",
       "1               0               0  \n",
       "2               1               1  \n",
       "3               0               0  \n",
       "4               0               0  \n",
       "...           ...             ...  \n",
       "27746           0               0  \n",
       "27747           0               0  \n",
       "27748           1               0  \n",
       "27749           0               1  \n",
       "27750           0               0  \n",
       "\n",
       "[27751 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# age_band 가 0과 1이 모두 있는 행 삭제\n",
    "ids_with_both = df.groupby('id_student')['age_band'].nunique()\n",
    "ids_with_both = ids_with_both[ids_with_both > 1].index\n",
    "df = df[~df['id_student'].isin(ids_with_both)].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3acf8a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27751 entries, 0 to 27750\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id_student         27751 non-null  int64  \n",
      " 1   gender             27751 non-null  int64  \n",
      " 2   region             27751 non-null  int64  \n",
      " 3   highest_education  27751 non-null  int64  \n",
      " 4   imd_band           27751 non-null  float64\n",
      " 5   age_band           27751 non-null  int64  \n",
      " 6   disability         27751 non-null  int64  \n",
      " 7   dropout_status     27751 non-null  int64  \n",
      "dtypes: float64(1), int64(7)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "400f3546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id_student           0\n",
       "gender               0\n",
       "region               0\n",
       "highest_education    0\n",
       "imd_band             0\n",
       "age_band             0\n",
       "disability           0\n",
       "dropout_status       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18cbd4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2d6ef0",
   "metadata": {},
   "source": [
    "### 데이터 학습 및 평가 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68a8970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분리 & 평가\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "# 분류 모델들\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# 부스팅 계열\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0666dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d55bb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['dropout_status', 'id_student'], axis=1)\n",
    "y = df['dropout_status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27fe63bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. 비교 모델 세트 ===\n",
    "models = {\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),  \n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        random_state=42,\n",
    "        eval_metric=\"logloss\"\n",
    "    ),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c21fe838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model comparison (no stratify, no scaling) ===\n",
      "           Model  Accuracy  Precision(1)  Recall(1)    F1(1)  ROC-AUC  TP  FP   TN   FN\n",
      "GradientBoosting  0.681464      0.407895   0.014117 0.027289 0.588619  31  45 4697 2165\n",
      "         XGBoost  0.679158      0.461735   0.082423 0.139876 0.564365 181 211 4531 2015\n",
      "    RandomForest  0.660853      0.399230   0.141621 0.209076 0.542940 311 468 4274 1885\n",
      "    DecisionTree  0.666186      0.395833   0.103825 0.164502 0.540689 228 348 4394 1968\n",
      "             KNN  0.634621      0.371494   0.223133 0.278805 0.537551 490 829 3913 1706\n",
      "\n",
      "Best (by ROC-AUC): GradientBoosting\n"
     ]
    }
   ],
   "source": [
    "# --- 2) 학습 & 평가 유틸 ---\n",
    "def eval_model(name, model, X_tr, y_tr, X_te, y_te):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_te)\n",
    "\n",
    "    # 확률 점수 얻기 (predict_proba가 없으면 decision_function을 확률처럼 정규화)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_score = model.predict_proba(X_te)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        df = model.decision_function(X_te)\n",
    "        # min-max로 [0,1] 스케일 (순위 기반 ROC-AUC에는 큰 문제 없음)\n",
    "        df_min, df_max = df.min(), df.max()\n",
    "        y_score = (df - df_min) / (df_max - df_min + 1e-9)\n",
    "    else:\n",
    "        # 확률이 전혀 없으면 예측(0/1)로 대체(ROC-AUC는 덜 의미 있음)\n",
    "        y_score = y_pred\n",
    "\n",
    "    rep = classification_report(y_te, y_pred, output_dict=True, zero_division=0)\n",
    "    auc = roc_auc_score(y_te, y_score)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_te, y_pred).ravel()\n",
    "\n",
    "    row = {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": rep[\"accuracy\"],\n",
    "        \"Precision(1)\": rep[\"1\"][\"precision\"],\n",
    "        \"Recall(1)\": rep[\"1\"][\"recall\"],\n",
    "        \"F1(1)\": rep[\"1\"][\"f1-score\"],\n",
    "        \"ROC-AUC\": auc,\n",
    "        \"TP\": tp, \"FP\": fp, \"TN\": tn, \"FN\": fn\n",
    "    }\n",
    "    return row, rep\n",
    "\n",
    "# --- 3) 전체 모델 실행 ---\n",
    "rows = []\n",
    "reports = {}\n",
    "for name, m in models.items():\n",
    "    try:\n",
    "        row, rep = eval_model(name, m, X_train, y_train, X_test, y_test)\n",
    "        rows.append(row)\n",
    "        reports[name] = rep\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] {name} 실행 중 오류 → 스킵: {e}\")\n",
    "\n",
    "df_results = pd.DataFrame(rows).sort_values(\"ROC-AUC\", ascending=False)\n",
    "print(\"=== Model comparison (no stratify, no scaling) ===\")\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "best_model_name = df_results.iloc[0][\"Model\"]\n",
    "print(f\"\\nBest (by ROC-AUC): {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9bfa6215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score      support\n",
      "0              0.684494  0.990510  0.809548  4742.000000\n",
      "1              0.407895  0.014117  0.027289  2196.000000\n",
      "accuracy       0.681464  0.681464  0.681464     0.681464\n",
      "macro avg      0.546195  0.502313  0.418419  6938.000000\n",
      "weighted avg   0.596946  0.681464  0.561949  6938.000000\n"
     ]
    }
   ],
   "source": [
    "df11= pd.DataFrame(reports['GradientBoosting'])\n",
    "print(df11.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f8a8e86",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(classification_report(y_test, \u001b[43my_pred\u001b[49m, digits=\u001b[32m4\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b209bbf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61234c56",
   "metadata": {},
   "source": [
    "### polynomial features 생성으로 성능 향상 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "45b4b822",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['dropout_status', 'id_student'], axis=1)\n",
    "y = df['dropout_status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train_strat, X_test_strat, y_train_strat, y_test_strat = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c91ef060",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "\n",
    "# === 1. 비교 모델 세트 ===\n",
    "models = {\n",
    "    # --- 선형 모델 + PolynomialFeatures ---\n",
    "    \"LogisticRegression_poly\": make_pipeline(\n",
    "        PolynomialFeatures(degree=2, include_bias=False),\n",
    "        StandardScaler(),\n",
    "        LogisticRegression(max_iter=1000, random_state=42)\n",
    "    ),\n",
    "    \"RidgeClassifier_poly\": make_pipeline(\n",
    "        PolynomialFeatures(degree=2, include_bias=False),\n",
    "        StandardScaler(),\n",
    "        RidgeClassifier(random_state=42)\n",
    "    ),\n",
    "\n",
    "    # --- 트리 계열 (PolynomialFeatures 넣어도 영향은 적지만 비교용) ---\n",
    "    \"DecisionTree_poly\": make_pipeline(\n",
    "        PolynomialFeatures(degree=2, include_bias=False),\n",
    "        DecisionTreeClassifier(random_state=42)\n",
    "    ),\n",
    "    \"RandomForest_poly\": make_pipeline(\n",
    "        PolynomialFeatures(degree=2, include_bias=False),\n",
    "        RandomForestClassifier(random_state=42)\n",
    "    ),\n",
    "    \"GradientBoosting_poly\": make_pipeline(\n",
    "        PolynomialFeatures(degree=2, include_bias=False),\n",
    "        GradientBoostingClassifier(random_state=42)\n",
    "    ),\n",
    "    \"XGBoost_poly\": make_pipeline(\n",
    "        PolynomialFeatures(degree=2, include_bias=False),\n",
    "        XGBClassifier(random_state=42, eval_metric=\"logloss\")\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3fba2df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model comparison (no stratify, scaling) ===\n",
      "                  Model  Accuracy  Precision(1)  Recall(1)    F1(1)  ROC-AUC  TP  FP   TN   FN\n",
      "  GradientBoosting_poly  0.681320      0.415730   0.016849 0.032385 0.589155  37  52 4690 2159\n",
      "LogisticRegression_poly  0.683915      0.519481   0.018215 0.035196 0.582029  40  37 4705 2156\n",
      "   RidgeClassifier_poly  0.683626      0.507463   0.015483 0.030049 0.582013  34  33 4709 2162\n",
      "           XGBoost_poly  0.674258      0.424171   0.081512 0.136746 0.562770 179 243 4499 2017\n",
      "      RandomForest_poly  0.661430      0.402299   0.143443 0.211480 0.543060 315 468 4274 1881\n",
      "      DecisionTree_poly  0.666186      0.395833   0.103825 0.164502 0.540670 228 348 4394 1968\n",
      "\n",
      "Best (by ROC-AUC): GradientBoosting_poly\n"
     ]
    }
   ],
   "source": [
    "# --- 2) 학습 & 평가 유틸 ---\n",
    "def eval_model(name, model, X_tr, y_tr, X_te, y_te):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_te)\n",
    "\n",
    "    # 확률 점수 얻기 (predict_proba가 없으면 decision_function을 확률처럼 정규화)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_score = model.predict_proba(X_te)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        df = model.decision_function(X_te)\n",
    "        # min-max로 [0,1] 스케일 (순위 기반 ROC-AUC에는 큰 문제 없음)\n",
    "        df_min, df_max = df.min(), df.max()\n",
    "        y_score = (df - df_min) / (df_max - df_min + 1e-9)\n",
    "    else:\n",
    "        # 확률이 전혀 없으면 예측(0/1)로 대체(ROC-AUC는 덜 의미 있음)\n",
    "        y_score = y_pred\n",
    "\n",
    "    rep = classification_report(y_te, y_pred, output_dict=True, zero_division=0)\n",
    "    auc = roc_auc_score(y_te, y_score)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_te, y_pred).ravel()\n",
    "\n",
    "    row = {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": rep[\"accuracy\"],\n",
    "        \"Precision(1)\": rep[\"1\"][\"precision\"],\n",
    "        \"Recall(1)\": rep[\"1\"][\"recall\"],\n",
    "        \"F1(1)\": rep[\"1\"][\"f1-score\"],\n",
    "        \"ROC-AUC\": auc,\n",
    "        \"TP\": tp, \"FP\": fp, \"TN\": tn, \"FN\": fn\n",
    "    }\n",
    "    return row, rep\n",
    "\n",
    "# --- 3) 전체 모델 실행 ---\n",
    "rows = []\n",
    "reports = {}\n",
    "for name, m in models.items():\n",
    "    try:\n",
    "        row, rep = eval_model(name, m, X_train, y_train, X_test, y_test)\n",
    "        rows.append(row)\n",
    "        reports[name] = rep\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] {name} 실행 중 오류 → 스킵: {e}\")\n",
    "\n",
    "df_results = pd.DataFrame(rows).sort_values(\"ROC-AUC\", ascending=False)\n",
    "print(\"=== Model comparison (no stratify, scaling) ===\")\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "best_model_name = df_results.iloc[0][\"Model\"]\n",
    "print(f\"\\nBest (by ROC-AUC): {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "27ad9d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Model comparison (stratify, scaling) ===\n",
      "                  Model  Accuracy  Precision(1)  Recall(1)    F1(1)  ROC-AUC  TP  FP   TN   FN\n",
      "  GradientBoosting_poly  0.680455      0.419643   0.021373 0.040675 0.583163  47  65 4674 2152\n",
      "LogisticRegression_poly  0.679591      0.388889   0.019100 0.036411 0.578448  42  66 4673 2157\n",
      "   RidgeClassifier_poly  0.680455      0.404255   0.017281 0.033144 0.578289  38  56 4683 2161\n",
      "           XGBoost_poly  0.670943      0.393939   0.070941 0.120231 0.557432 156 240 4499 2043\n",
      "      RandomForest_poly  0.653935      0.363144   0.121874 0.182499 0.539385 268 470 4269 1931\n",
      "      DecisionTree_poly  0.662871      0.373646   0.094134 0.150381 0.538034 207 347 4392 1992\n",
      "\n",
      "Best (by ROC-AUC): GradientBoosting_poly\n"
     ]
    }
   ],
   "source": [
    "# --- 3) 전체 모델 실행 ---\n",
    "rows = []\n",
    "reports = {}\n",
    "for name, m in models.items():\n",
    "    try:\n",
    "        row, rep = eval_model(name, m, X_train_strat, y_train_strat, X_test_strat, y_test_strat)\n",
    "        rows.append(row)\n",
    "        reports[name] = rep\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] {name} 실행 중 오류 → 스킵: {e}\")\n",
    "\n",
    "df_results = pd.DataFrame(rows).sort_values(\"ROC-AUC\", ascending=False)\n",
    "print(\"=== Model comparison (stratify, scaling) ===\")\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "best_model_name = df_results.iloc[0][\"Model\"]\n",
    "print(f\"\\nBest (by ROC-AUC): {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa822f0f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1709be",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 튜닝 추가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64073628",
   "metadata": {},
   "source": [
    "### 적은 범위 RandomSearchCV 하이퍼파라미터 튜닝 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88d3a138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 튜닝 시작: LogisticRegression_poly ---\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "최적의 하이퍼파라미터: {'polynomialfeatures__degree': 1, 'logisticregression__C': 10}\n",
      "--- 튜닝 시작: RidgeClassifier_poly ---\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "최적의 하이퍼파라미터: {'ridgeclassifier__alpha': 100, 'polynomialfeatures__degree': 1}\n",
      "--- 튜닝 시작: DecisionTree_poly ---\n",
      "--- 튜닝 시작: RandomForest_poly ---\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m param_grids:\n\u001b[32m     34\u001b[39m     \u001b[38;5;66;03m# RandomizedSearchCV 사용 (더 효율적)\u001b[39;00m\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# n_iter: 무작위 샘플링 횟수, cv: 교차 검증 폴드 수\u001b[39;00m\n\u001b[32m     36\u001b[39m     search = RandomizedSearchCV(\n\u001b[32m     37\u001b[39m         m, param_grids[name], n_iter=\u001b[32m10\u001b[39m, cv=\u001b[32m3\u001b[39m, scoring=\u001b[33m'\u001b[39m\u001b[33mroc_auc\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m     38\u001b[39m         n_jobs=-\u001b[32m1\u001b[39m, random_state=\u001b[32m42\u001b[39m, verbose=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[43msearch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# 최적의 모델로 교체하고 평가 진행\u001b[39;00m\n\u001b[32m     42\u001b[39m     best_model = search.best_estimator_\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1024\u001b[39m, in \u001b[36mBaseSearchCV.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m   1018\u001b[39m     results = \u001b[38;5;28mself\u001b[39m._format_results(\n\u001b[32m   1019\u001b[39m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[32m   1020\u001b[39m     )\n\u001b[32m   1022\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[32m   1027\u001b[39m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[32m   1028\u001b[39m first_test_score = all_out[\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtest_scores\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1951\u001b[39m, in \u001b[36mRandomizedSearchCV._run_search\u001b[39m\u001b[34m(self, evaluate_candidates)\u001b[39m\n\u001b[32m   1949\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[32m   1950\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1952\u001b[39m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1953\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\n\u001b[32m   1954\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1955\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[39m, in \u001b[36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[39m\u001b[34m(candidate_params, cv, more_results)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m    964\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[33m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[33m candidates,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    965\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[33m fits\u001b[39m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    966\u001b[39m             n_splits, n_candidates, n_candidates * n_splits\n\u001b[32m    967\u001b[39m         )\n\u001b[32m    968\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m970\u001b[39m out = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    981\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    983\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    984\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplitter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    986\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    988\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) < \u001b[32m1\u001b[39m:\n\u001b[32m    989\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    990\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo fits were performed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    991\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWas the CV iterator empty? \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    992\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWere there no candidates?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    993\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\joblib\\parallel.py:2072\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2070\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2072\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\joblib\\parallel.py:1682\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1679\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1681\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1684\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1688\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\ml_env\\Lib\\site-packages\\joblib\\parallel.py:1800\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1789\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1791\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1797\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1799\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1800\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1801\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1803\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1805\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1812\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# 튜닝할 하이퍼파라미터 공간 정의\n",
    "# Pipeline에서 각 단계의 하이퍼파라미터는 '단계이름__하이퍼파라미터' 형식으로 지정\n",
    "param_grids = {\n",
    "    # 로지스틱 회귀: C(규제 강도)와 PolynomialFeatures의 degree 튜닝\n",
    "    \"LogisticRegression_poly\": {\n",
    "        'polynomialfeatures__degree': [1, 2, 3],\n",
    "        'logisticregression__C': [0.01, 0.1, 1, 10, 100],\n",
    "    },\n",
    "    # 릿지 분류기: alpha(규제 강도)와 degree 튜닝\n",
    "    \"RidgeClassifier_poly\": {\n",
    "        'polynomialfeatures__degree': [1, 2, 3],\n",
    "        'ridgeclassifier__alpha': [0.01, 0.1, 1, 10, 100],\n",
    "    },\n",
    "    # 랜덤 포레스트: n_estimators, max_depth 튜닝\n",
    "    \"RandomForest_poly\": {\n",
    "        'randomforestclassifier__n_estimators': [100, 200, 300],\n",
    "        'randomforestclassifier__max_depth': [5, 10, None], # None은 깊이 제한 없음\n",
    "    },\n",
    "    # XGBoost: n_estimators, learning_rate, max_depth 튜닝\n",
    "    \"XGBoost_poly\": {\n",
    "        'xgbclassifier__n_estimators': [100, 200, 300],\n",
    "        'xgbclassifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'xgbclassifier__max_depth': [3, 5, 7],\n",
    "    }\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, m in models.items():\n",
    "    try:\n",
    "        print(f\"--- 튜닝 시작: {name} ---\")\n",
    "        if name in param_grids:\n",
    "            # RandomizedSearchCV 사용 (더 효율적)\n",
    "            # n_iter: 무작위 샘플링 횟수, cv: 교차 검증 폴드 수\n",
    "            search = RandomizedSearchCV(\n",
    "                m, param_grids[name], n_iter=10, cv=3, scoring='roc_auc', \n",
    "                n_jobs=-1, random_state=42, verbose=1)\n",
    "            search.fit(X_train, y_train)\n",
    "            \n",
    "            # 최적의 모델로 교체하고 평가 진행\n",
    "            best_model = search.best_estimator_\n",
    "            row, _ = eval_model(f\"{name}_tuned\", best_model, X_train, y_train, X_test, y_test)\n",
    "            rows.append(row)\n",
    "            \n",
    "            print(f\"최적의 하이퍼파라미터: {search.best_params_}\")\n",
    "        else:\n",
    "            # 튜닝 설정이 없는 모델은 기존 방식대로 평가\n",
    "            row, _ = eval_model(name, m, X_train, y_train, X_test, y_test)\n",
    "            rows.append(row)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] {name} 튜닝/실행 중 오류 → 스킵: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd4ff30",
   "metadata": {},
   "source": [
    "### 적은 범위 GridSearchCV 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1721cc23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 튜닝 시작: LogisticRegression_poly ---\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "최적의 하이퍼파라미터: {'logisticregression__C': 100, 'polynomialfeatures__degree': 1}\n",
      "--- 튜닝 시작: RidgeClassifier_poly ---\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "최적의 하이퍼파라미터: {'polynomialfeatures__degree': 1, 'ridgeclassifier__alpha': 100}\n",
      "--- 튜닝 시작: DecisionTree_poly ---\n",
      "--- 튜닝 시작: RandomForest_poly ---\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "최적의 하이퍼파라미터: {'randomforestclassifier__max_depth': 5, 'randomforestclassifier__n_estimators': 300}\n",
      "--- 튜닝 시작: GradientBoosting_poly ---\n",
      "--- 튜닝 시작: XGBoost_poly ---\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "최적의 하이퍼파라미터: {'xgbclassifier__learning_rate': 0.1, 'xgbclassifier__max_depth': 3, 'xgbclassifier__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# 튜닝할 하이퍼파라미터 공간 정의\n",
    "# Pipeline에서 각 단계의 하이퍼파라미터는 '단계이름__하이퍼파라미터' 형식으로 지정\n",
    "param_grids = {\n",
    "    # 로지스틱 회귀: C(규제 강도)와 PolynomialFeatures의 degree 튜닝\n",
    "    \"LogisticRegression_poly\": {\n",
    "        'polynomialfeatures__degree': [1, 2, 3],\n",
    "        'logisticregression__C': [0.01, 0.1, 1, 10, 100],\n",
    "    },\n",
    "    # 릿지 분류기: alpha(규제 강도)와 degree 튜닝\n",
    "    \"RidgeClassifier_poly\": {\n",
    "        'polynomialfeatures__degree': [1, 2, 3],\n",
    "        'ridgeclassifier__alpha': [0.01, 0.1, 1, 10, 100],\n",
    "    },\n",
    "    # 랜덤 포레스트: n_estimators, max_depth 튜닝\n",
    "    \"RandomForest_poly\": {\n",
    "        'randomforestclassifier__n_estimators': [100, 200, 300],\n",
    "        'randomforestclassifier__max_depth': [5, 10, None], # None은 깊이 제한 없음\n",
    "    },\n",
    "    # XGBoost: n_estimators, learning_rate, max_depth 튜닝\n",
    "    \"XGBoost_poly\": {\n",
    "        'xgbclassifier__n_estimators': [100, 200, 300],\n",
    "        'xgbclassifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'xgbclassifier__max_depth': [3, 5, 7],\n",
    "    }\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, m in models.items():\n",
    "    try:\n",
    "        print(f\"--- 튜닝 시작: {name} ---\")\n",
    "        if name in param_grids:\n",
    "            # GridSearchCV 사용 (더 효율적)\n",
    "            search = GridSearchCV(\n",
    "                m, param_grids[name], cv=3, scoring='roc_auc', \n",
    "                n_jobs=-1, verbose=1)\n",
    "            search.fit(X_train, y_train)\n",
    "            \n",
    "            # 최적의 모델로 교체하고 평가 진행\n",
    "            best_model = search.best_estimator_\n",
    "            row, _ = eval_model(f\"{name}_tuned\", best_model, X_train, y_train, X_test, y_test)\n",
    "            rows.append(row)\n",
    "            \n",
    "            print(f\"최적의 하이퍼파라미터: {search.best_params_}\")\n",
    "        else:\n",
    "            # 튜닝 설정이 없는 모델은 기존 방식대로 평가\n",
    "            row, _ = eval_model(name, m, X_train, y_train, X_test, y_test)\n",
    "            rows.append(row)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] {name} 튜닝/실행 중 오류 → 스킵: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5454c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    # 로지스틱 회귀: C(규제 강도)와 PolynomialFeatures의 degree 튜닝\n",
    "    \"LogisticRegression_poly\": {\n",
    "        'polynomialfeatures__degree': 1, \n",
    "        'logisticregression__C': 100\n",
    "    },\n",
    "    # 릿지 분류기: alpha(규제 강도)와 degree 튜닝\n",
    "    \"RidgeClassifier_poly\": {\n",
    "        'ridgeclassifier__alpha': 100, \n",
    "        'polynomialfeatures__degree': 1\n",
    "    },\n",
    "    # 랜덤 포레스트: n_estimators, max_depth 튜닝\n",
    "    \"RandomForest_poly\": {\n",
    "        'randomforestclassifier__n_estimators': 300, \n",
    "        'randomforestclassifier__max_depth': 5\n",
    "    },\n",
    "    # XGBoost: n_estimators, learning_rate, max_depth 튜닝\n",
    "    \"XGBoost_poly\": {\n",
    "        'xgbclassifier__n_estimators': 100, \n",
    "        'xgbclassifier__max_depth': 3, \n",
    "        'xgbclassifier__learning_rate': 0.1\n",
    "    }\n",
    "}\n",
    "\n",
    "best_lr_model = make_pipeline(\n",
    "    PolynomialFeatures(degree=param_grids['LogisticRegression_poly']['polynomialfeatures__degree'], include_bias=False),\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(C=param_grids['LogisticRegression_poly']['logisticregression__C'], max_iter=1000, random_state=42)\n",
    ")\n",
    "\n",
    "best_ridge_model = make_pipeline(\n",
    "    PolynomialFeatures(degree=param_grids['RidgeClassifier_poly']['polynomialfeatures__degree'], include_bias=False),\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(C=param_grids['RidgeClassifier_poly']['ridgeclassifier__alpha'], max_iter=1000, random_state=42)\n",
    ")\n",
    "\n",
    "best_rf_model = make_pipeline(\n",
    "    PolynomialFeatures(degree=2, include_bias=False),\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "best_xgb_model = make_pipeline(\n",
    "    PolynomialFeatures(degree=2, include_bias=False),\n",
    "    XGBClassifier(\n",
    "        n_estimators = 100,\n",
    "        max_depth = 3,\n",
    "        learning_rate = 0.1,\n",
    "        random_state = 42,\n",
    "        eval_metrics = 'logloss'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef09f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {\n",
    "    \"LogisticRegression_poly_tuned\": best_lr_model,\n",
    "    \"RidgeClassifier_poly_tuned\": best_ridge_model,\n",
    "    \"RandomForest_poly_tuned\": best_rf_model,\n",
    "    \"XGBoost_poly_tuned\": best_xgb_model\n",
    "}\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfe01d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Tuned Model Performance ===\n",
      "                        Model  Accuracy  Precision(1)  Recall(1)    F1(1)  ROC-AUC  TP  FP   TN   FN\n",
      "           XGBoost_poly_tuned  0.684491      0.537634   0.022769 0.043687 0.587819  50  43 4699 2146\n",
      "      RandomForest_poly_tuned  0.684059      0.700000   0.003188 0.006346 0.585209   7   3 4739 2189\n",
      "   RidgeClassifier_poly_tuned  0.682473      0.000000   0.000000 0.000000 0.574262   0   7 4735 2196\n",
      "LogisticRegression_poly_tuned  0.682473      0.000000   0.000000 0.000000 0.574262   0   7 4735 2196\n",
      "\n",
      "Best Final Model (by ROC-AUC): XGBoost_poly_tuned\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "reports = {}\n",
    "\n",
    "def eval_model(name, model, X_tr, y_tr, X_te, y_te):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_te)\n",
    "\n",
    "    # 확률 점수 얻기 (predict_proba가 없으면 decision_function을 확률처럼 정규화)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_score = model.predict_proba(X_te)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        df = model.decision_function(X_te)\n",
    "        # min-max로 [0,1] 스케일 (순위 기반 ROC-AUC에는 큰 문제 없음)\n",
    "        df_min, df_max = df.min(), df.max()\n",
    "        y_score = (df - df_min) / (df_max - df_min + 1e-9)\n",
    "    else:\n",
    "        # 확률이 전혀 없으면 예측(0/1)로 대체(ROC-AUC는 덜 의미 있음)\n",
    "        y_score = y_pred\n",
    "\n",
    "    rep = classification_report(y_te, y_pred, output_dict=True, zero_division=0)\n",
    "    auc = roc_auc_score(y_te, y_score)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_te, y_pred).ravel()\n",
    "\n",
    "    row = {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": rep[\"accuracy\"],\n",
    "        \"Precision(1)\": rep[\"1\"][\"precision\"],\n",
    "        \"Recall(1)\": rep[\"1\"][\"recall\"],\n",
    "        \"F1(1)\": rep[\"1\"][\"f1-score\"],\n",
    "        \"ROC-AUC\": auc,\n",
    "        \"TP\": tp, \"FP\": fp, \"TN\": tn, \"FN\": fn\n",
    "    }\n",
    "    return row, rep\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    row, rep = eval_model(name, model, X_train, y_train, X_test, y_test)\n",
    "    rows.append(row)\n",
    "    reports[name] = rep\n",
    "\n",
    "import pandas as pd\n",
    "df_results_tuned = pd.DataFrame(rows).sort_values(\"ROC-AUC\", ascending=False)\n",
    "\n",
    "print(\"=== Final Tuned Model Performance ===\")\n",
    "print(df_results_tuned.to_string(index=False))\n",
    "\n",
    "best_final_model_name = df_results_tuned.iloc[0][\"Model\"]\n",
    "print(f\"\\nBest Final Model (by ROC-AUC): {best_final_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fda930e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3360dbef",
   "metadata": {},
   "source": [
    "### 파생변수 추가 후 GridSearchCV 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bfe9e61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 31154 entries, 0 to 31481\n",
      "Data columns (total 37 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   id_student               31154 non-null  int64  \n",
      " 1   gender                   31154 non-null  int64  \n",
      " 2   region                   31154 non-null  int64  \n",
      " 3   highest_education        31154 non-null  int64  \n",
      " 4   imd_band                 31154 non-null  int64  \n",
      " 5   age_band                 31154 non-null  int64  \n",
      " 6   disability               31154 non-null  int64  \n",
      " 7   highest_education_score  31154 non-null  float64\n",
      " 8   age_band_score           31154 non-null  int64  \n",
      " 9   age_band_mid             31154 non-null  float64\n",
      " 10  imd_band_numeric         31154 non-null  float64\n",
      " 11  imd_inverse              31154 non-null  float64\n",
      " 12  edu_income_score         31154 non-null  float64\n",
      " 13  age_edu_gap              31154 non-null  float64\n",
      " 14  is_old                   31154 non-null  int64  \n",
      " 15  is_postgrad              31154 non-null  int64  \n",
      " 16  is_disabled              31154 non-null  int64  \n",
      " 17  is_female                31154 non-null  int64  \n",
      " 18  is_high_income_region    31154 non-null  int64  \n",
      " 19  is_high_edu              31154 non-null  int64  \n",
      " 20  edu_age                  31154 non-null  int64  \n",
      " 21  imd_region               31154 non-null  int64  \n",
      " 22  genderdisability         31154 non-null  int64  \n",
      " 23  regionedu                31154 non-null  int64  \n",
      " 24  gender_imd               31154 non-null  int64  \n",
      " 25  disability_imd           31154 non-null  int64  \n",
      " 26  region_count             31154 non-null  int64  \n",
      " 27  region_share             31154 non-null  float64\n",
      " 28  edu_global_share         31154 non-null  float64\n",
      " 29  age_global_share         31154 non-null  float64\n",
      " 30  gender_in_region_share   31154 non-null  float64\n",
      " 31  age_in_region_share      31154 non-null  float64\n",
      " 32  region_disability_rate   31154 non-null  float64\n",
      " 33  region_avg_credit        31154 non-null  float64\n",
      " 34  edu_region_avg_credit    31154 non-null  float64\n",
      " 35  age_avg_credit           31154 non-null  float64\n",
      " 36  target                   31154 non-null  int64  \n",
      "dtypes: float64(15), int64(22)\n",
      "memory usage: 9.0 MB\n"
     ]
    }
   ],
   "source": [
    "df_out = pd.read_csv('./data/data_data_data.csv')\n",
    "df_out = df_out.dropna()\n",
    "df_out.isnull().sum()\n",
    "df_out.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8367fd82",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m X = \u001b[43mdf_out\u001b[49m.drop([\u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mid_student\u001b[39m\u001b[33m'\u001b[39m], axis=\u001b[32m1\u001b[39m)\n\u001b[32m      2\u001b[39m y = df_out[\u001b[33m'\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      4\u001b[39m X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=\u001b[32m42\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df_out' is not defined"
     ]
    }
   ],
   "source": [
    "X = df_out.drop(['target', 'id_student'], axis=1)\n",
    "y = df_out['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6160a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 튜닝 시작: LogisticRegression_poly ---\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "최적의 하이퍼파라미터: {'logisticregression__C': 0.1, 'polynomialfeatures__degree': 2}\n",
      "--- 튜닝 시작: RidgeClassifier_poly ---\n",
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n",
      "최적의 하이퍼파라미터: {'polynomialfeatures__degree': 2, 'ridgeclassifier__alpha': 100}\n",
      "--- 튜닝 시작: DecisionTree_poly ---\n",
      "--- 튜닝 시작: RandomForest_poly ---\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "최적의 하이퍼파라미터: {'randomforestclassifier__max_depth': 5, 'randomforestclassifier__n_estimators': 300}\n",
      "--- 튜닝 시작: GradientBoosting_poly ---\n",
      "--- 튜닝 시작: XGBoost_poly ---\n",
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "최적의 하이퍼파라미터: {'xgbclassifier__learning_rate': 0.01, 'xgbclassifier__max_depth': 3, 'xgbclassifier__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# 튜닝할 하이퍼파라미터 공간 정의\n",
    "# Pipeline에서 각 단계의 하이퍼파라미터는 '단계이름__하이퍼파라미터' 형식으로 지정\n",
    "param_grids = {\n",
    "    # 로지스틱 회귀: C(규제 강도)와 PolynomialFeatures의 degree 튜닝\n",
    "    \"LogisticRegression_poly\": {\n",
    "        'polynomialfeatures__degree': [1, 2, 3],\n",
    "        'logisticregression__C': [0.01, 0.1, 1, 10, 100],\n",
    "    },\n",
    "    # 릿지 분류기: alpha(규제 강도)와 degree 튜닝\n",
    "    \"RidgeClassifier_poly\": {\n",
    "        'polynomialfeatures__degree': [1, 2, 3],\n",
    "        'ridgeclassifier__alpha': [0.01, 0.1, 1, 10, 100],\n",
    "    },\n",
    "    # 랜덤 포레스트: n_estimators, max_depth 튜닝\n",
    "    \"RandomForest_poly\": {\n",
    "        'randomforestclassifier__n_estimators': [100, 200, 300],\n",
    "        'randomforestclassifier__max_depth': [5, 10, None], # None은 깊이 제한 없음\n",
    "    },\n",
    "    # XGBoost: n_estimators, learning_rate, max_depth 튜닝\n",
    "    \"XGBoost_poly\": {\n",
    "        'xgbclassifier__n_estimators': [100, 200, 300],\n",
    "        'xgbclassifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'xgbclassifier__max_depth': [3, 5, 7],\n",
    "    }\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, m in models.items():\n",
    "    try:\n",
    "        print(f\"--- 튜닝 시작: {name} ---\")\n",
    "        if name in param_grids:\n",
    "            # GridSearchCV 사용 (더 효율적)\n",
    "            search = GridSearchCV(\n",
    "                m, param_grids[name], cv=3, scoring='roc_auc', \n",
    "                n_jobs=-1, verbose=1)\n",
    "            search.fit(X_train, y_train)\n",
    "            \n",
    "            # 최적의 모델로 교체하고 평가 진행\n",
    "            best_model = search.best_estimator_\n",
    "            row, _ = eval_model(f\"{name}_tuned\", best_model, X_train, y_train, X_test, y_test)\n",
    "            rows.append(row)\n",
    "            \n",
    "            print(f\"최적의 하이퍼파라미터: {search.best_params_}\")\n",
    "        else:\n",
    "            # 튜닝 설정이 없는 모델은 기존 방식대로 평가\n",
    "            row, _ = eval_model(name, m, X_train, y_train, X_test, y_test)\n",
    "            rows.append(row)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] {name} 튜닝/실행 중 오류 → 스킵: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7628263",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    # 로지스틱 회귀: C(규제 강도)와 PolynomialFeatures의 degree 튜닝\n",
    "    \"LogisticRegression_poly\": {\n",
    "        'polynomialfeatures__degree': 2, \n",
    "        'logisticregression__C': 0.1\n",
    "    },\n",
    "    # 릿지 분류기: alpha(규제 강도)와 degree 튜닝\n",
    "    \"RidgeClassifier_poly\": {\n",
    "        'ridgeclassifier__alpha': 100, \n",
    "        'polynomialfeatures__degree': 2\n",
    "    },\n",
    "    # 랜덤 포레스트: n_estimators, max_depth 튜닝\n",
    "    \"RandomForest_poly\": {\n",
    "        'randomforestclassifier__n_estimators': 300, \n",
    "        'randomforestclassifier__max_depth': 5\n",
    "    },\n",
    "    # XGBoost: n_estimators, learning_rate, max_depth 튜닝\n",
    "    \"XGBoost_poly\": {\n",
    "        'xgbclassifier__n_estimators': 200, \n",
    "        'xgbclassifier__max_depth': 3, \n",
    "        'xgbclassifier__learning_rate': 0.01\n",
    "    }\n",
    "}\n",
    "\n",
    "best_lr_model = make_pipeline(\n",
    "    PolynomialFeatures(degree=param_grids['LogisticRegression_poly']['polynomialfeatures__degree'], include_bias=False),\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(C=param_grids['LogisticRegression_poly']['logisticregression__C'], max_iter=1000, random_state=42)\n",
    ")\n",
    "\n",
    "best_ridge_model = make_pipeline(\n",
    "    PolynomialFeatures(degree=param_grids['RidgeClassifier_poly']['polynomialfeatures__degree'], include_bias=False),\n",
    "    StandardScaler(),\n",
    "    RidgeClassifier(alpha=param_grids['RidgeClassifier_poly']['ridgeclassifier__alpha'], max_iter=1000, random_state=42)\n",
    ")\n",
    "\n",
    "best_rf_model = make_pipeline(\n",
    "    PolynomialFeatures(degree=2, include_bias=False),\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "best_xgb_model = make_pipeline(\n",
    "    PolynomialFeatures(degree=2, include_bias=False),\n",
    "    XGBClassifier(\n",
    "        n_estimators = 200,\n",
    "        max_depth = 3,\n",
    "        learning_rate = 0.01,\n",
    "        random_state = 42,\n",
    "        eval_metrics = 'logloss'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27306473",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {\n",
    "    \"LogisticRegression_poly_tuned\": best_lr_model,\n",
    "    \"RidgeClassifier_poly_tuned\": best_ridge_model,\n",
    "    \"RandomForest_poly_tuned\": best_rf_model,\n",
    "    \"XGBoost_poly_tuned\": best_xgb_model\n",
    "}\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d72a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Tuned Model Performance ===\n",
      "                        Model  Accuracy  Precision(1)  Recall(1)    F1(1)  ROC-AUC  TP  FP   TN   FN\n",
      "      RandomForest_poly_tuned  0.688022      0.300000   0.001237 0.002463 0.585458   3   7 5356 2423\n",
      "           XGBoost_poly_tuned  0.688535      0.000000   0.000000 0.000000 0.584405   0   0 5363 2426\n",
      "LogisticRegression_poly_tuned  0.688022      0.469697   0.012778 0.024880 0.579505  31  35 5328 2395\n",
      "   RidgeClassifier_poly_tuned  0.687636      0.440678   0.010717 0.020926 0.578650  26  33 5330 2400\n",
      "\n",
      "Best Final Model (by ROC-AUC): RandomForest_poly_tuned\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "reports = {}\n",
    "\n",
    "def eval_model(name, model, X_tr, y_tr, X_te, y_te):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_te)\n",
    "\n",
    "    # 확률 점수 얻기 (predict_proba가 없으면 decision_function을 확률처럼 정규화)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_score = model.predict_proba(X_te)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        df = model.decision_function(X_te)\n",
    "        # min-max로 [0,1] 스케일 (순위 기반 ROC-AUC에는 큰 문제 없음)\n",
    "        df_min, df_max = df.min(), df.max()\n",
    "        y_score = (df - df_min) / (df_max - df_min + 1e-9)\n",
    "    else:\n",
    "        # 확률이 전혀 없으면 예측(0/1)로 대체(ROC-AUC는 덜 의미 있음)\n",
    "        y_score = y_pred\n",
    "\n",
    "    rep = classification_report(y_te, y_pred, output_dict=True, zero_division=0)\n",
    "    auc = roc_auc_score(y_te, y_score)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_te, y_pred).ravel()\n",
    "\n",
    "    row = {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": rep[\"accuracy\"],\n",
    "        \"Precision(1)\": rep[\"1\"][\"precision\"],\n",
    "        \"Recall(1)\": rep[\"1\"][\"recall\"],\n",
    "        \"F1(1)\": rep[\"1\"][\"f1-score\"],\n",
    "        \"ROC-AUC\": auc,\n",
    "        \"TP\": tp, \"FP\": fp, \"TN\": tn, \"FN\": fn\n",
    "    }\n",
    "    return row, rep\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    row, rep = eval_model(name, model, X_train, y_train, X_test, y_test)\n",
    "    rows.append(row)\n",
    "    reports[name] = rep\n",
    "\n",
    "import pandas as pd\n",
    "df_results_tuned = pd.DataFrame(rows).sort_values(\"ROC-AUC\", ascending=False)\n",
    "\n",
    "print(\"=== Final Tuned Model Performance ===\")\n",
    "print(df_results_tuned.to_string(index=False))\n",
    "\n",
    "best_final_model_name = df_results_tuned.iloc[0][\"Model\"]\n",
    "print(f\"\\nBest Final Model (by ROC-AUC): {best_final_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ea27c5",
   "metadata": {},
   "source": [
    "### 파생변수 추가 후 넓은 범위로 RandomSearchCV 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78e475b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 튜닝 시작: LogisticRegression_poly ---\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "최적의 하이퍼파라미터: {'polynomialfeatures__degree': 2, 'logisticregression__C': 0.001}\n",
      "--- 튜닝 시작: RidgeClassifier_poly ---\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "최적의 하이퍼파라미터: {'ridgeclassifier__alpha': 10, 'polynomialfeatures__degree': 2}\n",
      "--- 튜닝 시작: DecisionTree_poly ---\n",
      "--- 튜닝 시작: RandomForest_poly ---\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n",
      "최적의 하이퍼파라미터: {'randomforestclassifier__n_estimators': 300, 'randomforestclassifier__max_depth': 5}\n",
      "--- 튜닝 시작: GradientBoosting_poly ---\n",
      "--- 튜닝 시작: XGBoost_poly ---\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "최적의 하이퍼파라미터: {'xgbclassifier__n_estimators': 100, 'xgbclassifier__max_depth': 3, 'xgbclassifier__learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# 튜닝할 하이퍼파라미터 공간 정의\n",
    "# Pipeline에서 각 단계의 하이퍼파라미터는 '단계이름__하이퍼파라미터' 형식으로 지정\n",
    "param_grids = {\n",
    "    # 로지스틱 회귀: C(규제 강도)와 PolynomialFeatures의 degree 튜닝\n",
    "    \"LogisticRegression_poly\": {\n",
    "        'polynomialfeatures__degree': [1, 2, 3],\n",
    "        'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    },\n",
    "    # 릿지 분류기: alpha(규제 강도)와 degree 튜닝\n",
    "    \"RidgeClassifier_poly\": {\n",
    "        'polynomialfeatures__degree': [1, 2, 3],\n",
    "        'ridgeclassifier__alpha': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "    },\n",
    "    # 랜덤 포레스트: n_estimators, max_depth 튜닝\n",
    "    \"RandomForest_poly\": {\n",
    "        'randomforestclassifier__n_estimators': [100, 200, 300],\n",
    "        'randomforestclassifier__max_depth': [5, 10, None], # None은 깊이 제한 없음\n",
    "    },\n",
    "    # XGBoost: n_estimators, learning_rate, max_depth 튜닝\n",
    "    \"XGBoost_poly\": {\n",
    "        'xgbclassifier__n_estimators': [100, 200, 300],\n",
    "        'xgbclassifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "        'xgbclassifier__max_depth': [3, 5, 7],\n",
    "    }\n",
    "}\n",
    "\n",
    "rows = []\n",
    "for name, m in models.items():\n",
    "    try:\n",
    "        print(f\"--- 튜닝 시작: {name} ---\")\n",
    "        if name in param_grids:\n",
    "            # GridSearchCV 사용 (더 효율적)\n",
    "            search = RandomizedSearchCV(\n",
    "                m, param_grids[name], n_iter=10, cv=3, scoring='roc_auc', \n",
    "                n_jobs=-1, random_state=42, verbose=1)\n",
    "            search.fit(X_train, y_train)\n",
    "            \n",
    "            # 최적의 모델로 교체하고 평가 진행\n",
    "            best_model = search.best_estimator_\n",
    "            row, _ = eval_model(f\"{name}_tuned\", best_model, X_train, y_train, X_test, y_test)\n",
    "            rows.append(row)\n",
    "            \n",
    "            print(f\"최적의 하이퍼파라미터: {search.best_params_}\")\n",
    "        else:\n",
    "            # 튜닝 설정이 없는 모델은 기존 방식대로 평가\n",
    "            row, _ = eval_model(name, m, X_train, y_train, X_test, y_test)\n",
    "            rows.append(row)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] {name} 튜닝/실행 중 오류 → 스킵: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9c3e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    # 로지스틱 회귀: C(규제 강도)와 PolynomialFeatures의 degree 튜닝\n",
    "    \"LogisticRegression_poly\": {\n",
    "        'polynomialfeatures__degree': 2, \n",
    "        'logisticregression__C': 0.001\n",
    "    },\n",
    "    # 릿지 분류기: alpha(규제 강도)와 degree 튜닝\n",
    "    \"RidgeClassifier_poly\": {\n",
    "        'ridgeclassifier__alpha': 10, \n",
    "        'polynomialfeatures__degree': 2\n",
    "    },\n",
    "    # 랜덤 포레스트: n_estimators, max_depth 튜닝\n",
    "    \"RandomForest_poly\": {\n",
    "        'randomforestclassifier__n_estimators': 300, \n",
    "        'randomforestclassifier__max_depth': 5\n",
    "    },\n",
    "    # XGBoost: n_estimators, learning_rate, max_depth 튜닝\n",
    "    \"XGBoost_poly\": {\n",
    "        'xgbclassifier__n_estimators': 100, \n",
    "        'xgbclassifier__max_depth': 3, \n",
    "        'xgbclassifier__learning_rate': 0.01\n",
    "    }\n",
    "}\n",
    "\n",
    "best_lr_model = make_pipeline(\n",
    "    PolynomialFeatures(degree=param_grids['LogisticRegression_poly']['polynomialfeatures__degree'], include_bias=False),\n",
    "    StandardScaler(),\n",
    "    LogisticRegression(C=param_grids['LogisticRegression_poly']['logisticregression__C'], max_iter=1000, random_state=42)\n",
    ")\n",
    "\n",
    "best_ridge_model = make_pipeline(\n",
    "    PolynomialFeatures(degree=param_grids['RidgeClassifier_poly']['polynomialfeatures__degree'], include_bias=False),\n",
    "    StandardScaler(),\n",
    "    RidgeClassifier(alpha=param_grids['RidgeClassifier_poly']['ridgeclassifier__alpha'], max_iter=1000, random_state=42)\n",
    ")\n",
    "\n",
    "best_rf_model = make_pipeline(\n",
    "    PolynomialFeatures(degree=2, include_bias=False),\n",
    "    RandomForestClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=5,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "best_xgb_model = make_pipeline(\n",
    "    PolynomialFeatures(degree=2, include_bias=False),\n",
    "    XGBClassifier(\n",
    "        n_estimators = 100,\n",
    "        max_depth = 3,\n",
    "        learning_rate = 0.01,\n",
    "        random_state = 42,\n",
    "        eval_metrics = 'logloss'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2989100",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {\n",
    "    \"LogisticRegression_poly_tuned\": best_lr_model,\n",
    "    \"RidgeClassifier_poly_tuned\": best_ridge_model,\n",
    "    \"RandomForest_poly_tuned\": best_rf_model,\n",
    "    \"XGBoost_poly_tuned\": best_xgb_model\n",
    "}\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8b339e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Final Tuned Model Performance ===\n",
      "                        Model  Accuracy  Precision(1)  Recall(1)    F1(1)  ROC-AUC  TP  FP   TN   FN\n",
      "      RandomForest_poly_tuned  0.688022      0.300000   0.001237 0.002463 0.585458   3   7 5356 2423\n",
      "           XGBoost_poly_tuned  0.688535      0.000000   0.000000 0.000000 0.583131   0   0 5363 2426\n",
      "   RidgeClassifier_poly_tuned  0.688022      0.466667   0.011542 0.022526 0.579596  28  32 5331 2398\n",
      "LogisticRegression_poly_tuned  0.688407      0.485714   0.007007 0.013816 0.577889  17  18 5345 2409\n",
      "\n",
      "Best Final Model (by ROC-AUC): RandomForest_poly_tuned\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "reports = {}\n",
    "\n",
    "def eval_model(name, model, X_tr, y_tr, X_te, y_te):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_te)\n",
    "\n",
    "    # 확률 점수 얻기 (predict_proba가 없으면 decision_function을 확률처럼 정규화)\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_score = model.predict_proba(X_te)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        df = model.decision_function(X_te)\n",
    "        # min-max로 [0,1] 스케일 (순위 기반 ROC-AUC에는 큰 문제 없음)\n",
    "        df_min, df_max = df.min(), df.max()\n",
    "        y_score = (df - df_min) / (df_max - df_min + 1e-9)\n",
    "    else:\n",
    "        # 확률이 전혀 없으면 예측(0/1)로 대체(ROC-AUC는 덜 의미 있음)\n",
    "        y_score = y_pred\n",
    "\n",
    "    rep = classification_report(y_te, y_pred, output_dict=True, zero_division=0)\n",
    "    auc = roc_auc_score(y_te, y_score)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_te, y_pred).ravel()\n",
    "\n",
    "    row = {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": rep[\"accuracy\"],\n",
    "        \"Precision(1)\": rep[\"1\"][\"precision\"],\n",
    "        \"Recall(1)\": rep[\"1\"][\"recall\"],\n",
    "        \"F1(1)\": rep[\"1\"][\"f1-score\"],\n",
    "        \"ROC-AUC\": auc,\n",
    "        \"TP\": tp, \"FP\": fp, \"TN\": tn, \"FN\": fn\n",
    "    }\n",
    "    return row, rep\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    row, rep = eval_model(name, model, X_train, y_train, X_test, y_test)\n",
    "    rows.append(row)\n",
    "    reports[name] = rep\n",
    "\n",
    "import pandas as pd\n",
    "df_results_tuned = pd.DataFrame(rows).sort_values(\"ROC-AUC\", ascending=False)\n",
    "\n",
    "print(\"=== Final Tuned Model Performance ===\")\n",
    "print(df_results_tuned.to_string(index=False))\n",
    "\n",
    "best_final_model_name = df_results_tuned.iloc[0][\"Model\"]\n",
    "print(f\"\\nBest Final Model (by ROC-AUC): {best_final_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82c8d05",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104800ef",
   "metadata": {},
   "source": [
    "## 모든 모델 성능 방법 총동원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "671c2ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_out.drop(['target', 'id_student'], axis=1)\n",
    "y = df_out['target']\n",
    "\n",
    "X_train_strat, X_test_strat, y_train_strat, y_test_strat = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "73865f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import numpy as np\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression_poly\": make_pipeline(\n",
    "        PolynomialFeatures(degree=2, include_bias=False),\n",
    "        StandardScaler(),\n",
    "        LogisticRegression(max_iter=2000, random_state=42, class_weight='balanced')\n",
    "    ),\n",
    "    \"RidgeClassifier_poly\": make_pipeline(\n",
    "        PolynomialFeatures(degree=2, include_bias=False),\n",
    "        StandardScaler(),\n",
    "        RidgeClassifier(random_state=42, class_weight='balanced')\n",
    "    ),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(random_state=42, class_weight='balanced'),\n",
    "    \"RandomForest\": RandomForestClassifier(random_state=42, class_weight='balanced'),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(random_state=42),  # GBoost는 class_weight 없음\n",
    "    \"XGBoost\": XGBClassifier(random_state=42, eval_metric=\"logloss\", scale_pos_weight=len(y_train_strat[y_train_strat==0]) / len(y_train_strat[y_train_strat==1]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "980792c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grids = {\n",
    "    \"LogisticRegression_poly\": {\n",
    "        \"logisticregression__C\": [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "    },\n",
    "    \"RidgeClassifier_poly\": {\n",
    "        \"ridgeclassifier__alpha\": [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "    },\n",
    "    \"DecisionTree\": {\n",
    "        \"max_depth\": [3, 5, None],\n",
    "        \"min_samples_split\": [2, 5, 10, 15]\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [None, 5, 10, 15]\n",
    "    },\n",
    "    \"GradientBoosting\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"learning_rate\": [0.05, 0.1, 0.2, 0.25]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        \"n_estimators\": [100, 200, 300],\n",
    "        \"max_depth\": [3, 5, 10],\n",
    "        \"learning_rate\": [0.05, 0.1, 0.2, 0.25]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7baff219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(name, model, X_tr, y_tr, X_te, y_te):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_te)\n",
    "\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_score = model.predict_proba(X_te)[:, 1]\n",
    "    elif hasattr(model, \"decision_function\"):\n",
    "        df = model.decision_function(X_te)\n",
    "        y_score = (df - df.min()) / (df.max() - df.min() + 1e-9)\n",
    "    else:\n",
    "        y_score = y_pred\n",
    "\n",
    "    rep = classification_report(y_te, y_pred, output_dict=True, zero_division=0)\n",
    "    auc = roc_auc_score(y_te, y_score)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_te, y_pred).ravel()\n",
    "\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": rep[\"accuracy\"],\n",
    "        \"Precision(1)\": rep[\"1\"][\"precision\"],\n",
    "        \"Recall(1)\": rep[\"1\"][\"recall\"],\n",
    "        \"F1(1)\": rep[\"1\"][\"f1-score\"],\n",
    "        \"ROC-AUC\": auc,\n",
    "        \"TP\": tp, \"FP\": fp, \"TN\": tn, \"FN\": fn\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "82819dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogisticRegression_poly] Best params: {'logisticregression__C': 0.1}\n",
      "[RidgeClassifier_poly] Best params: {'ridgeclassifier__alpha': 0.1}\n",
      "[DecisionTree] Best params: {'min_samples_split': 5, 'max_depth': 3}\n",
      "[RandomForest] Best params: {'n_estimators': 200, 'max_depth': None}\n",
      "[GradientBoosting] Best params: {'n_estimators': 100, 'learning_rate': 0.05}\n",
      "[XGBoost] Best params: {'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.05}\n",
      "\n",
      "=== Model comparison (Optimized with class_weight) ===\n",
      "                  Model  Accuracy  Precision(1)  Recall(1)    F1(1)  ROC-AUC   TP   FP   TN   FN\n",
      "       GradientBoosting  0.686481      0.520000   0.010638 0.020850 0.568192   26   24 5321 2418\n",
      "                XGBoost  0.556297      0.358580   0.524959 0.426104 0.568168 1283 2295 3050 1161\n",
      "LogisticRegression_poly  0.557838      0.360413   0.528232 0.428477 0.567257 1291 2291 3054 1153\n",
      "   RidgeClassifier_poly  0.555013      0.358056   0.527414 0.426539 0.566654 1289 2311 3034 1155\n",
      "           DecisionTree  0.524586      0.349797   0.599836 0.441899 0.554896 1466 2725 2620  978\n",
      "           RandomForest  0.549621      0.345797   0.488134 0.404818 0.543784 1193 2257 3088 1251\n"
     ]
    }
   ],
   "source": [
    "rows = {}\n",
    "for name, model in models.items():\n",
    "    search = RandomizedSearchCV(\n",
    "        model,\n",
    "        param_distributions=param_grids.get(name, {}),\n",
    "        n_iter=min(5, len(param_grids.get(name, {}))),\n",
    "        scoring='roc_auc',\n",
    "        cv=3,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    search.fit(X_train_strat, y_train_strat)\n",
    "    best_model = search.best_estimator_\n",
    "\n",
    "    row = eval_model(name, best_model, X_train_strat, y_train_strat, X_test_strat, y_test_strat)\n",
    "    rows[name] = row\n",
    "    print(f\"[{name}] Best params: {search.best_params_}\")\n",
    "\n",
    "df_results = pd.DataFrame(rows.values()).sort_values(\"ROC-AUC\", ascending=False)\n",
    "print(\"\\n=== Model comparison (Optimized with class_weight) ===\")\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1f5dfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogisticRegression_poly] Best params: {'logisticregression__C': 0.1}\n",
      "[RidgeClassifier_poly] Best params: {'ridgeclassifier__alpha': 100}\n",
      "[DecisionTree] Best params: {'max_depth': 5, 'min_samples_split': 2}\n",
      "[RandomForest] Best params: {'max_depth': 5, 'n_estimators': 200}\n",
      "[GradientBoosting] Best params: {'learning_rate': 0.05, 'n_estimators': 100}\n",
      "[XGBoost] Best params: {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 100}\n",
      "\n",
      "=== Model comparison (Optimized with class_weight) ===\n",
      "                  Model  Accuracy  Precision(1)  Recall(1)    F1(1)  ROC-AUC   TP   FP   TN   FN\n",
      "       GradientBoosting  0.686481      0.520000   0.010638 0.020850 0.568192   26   24 5321 2418\n",
      "                XGBoost  0.556297      0.358580   0.524959 0.426104 0.568168 1283 2295 3050 1161\n",
      "           RandomForest  0.553730      0.359477   0.540098 0.431655 0.567380 1320 2352 2993 1124\n",
      "LogisticRegression_poly  0.557838      0.360413   0.528232 0.428477 0.567257 1291 2291 3054 1153\n",
      "   RidgeClassifier_poly  0.559635      0.361517   0.526596 0.428714 0.567243 1287 2273 3072 1157\n",
      "           DecisionTree  0.540891      0.354872   0.566285 0.436318 0.561949 1384 2516 2829 1060\n"
     ]
    }
   ],
   "source": [
    "rows = {}\n",
    "for name, model in models.items():\n",
    "    search = GridSearchCV(\n",
    "        model,\n",
    "        param_grid=param_grids.get(name, {}),\n",
    "        scoring='roc_auc',\n",
    "        cv=3,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    search.fit(X_train_strat, y_train_strat)\n",
    "    best_model = search.best_estimator_\n",
    "\n",
    "    row = eval_model(name, best_model, X_train_strat, y_train_strat, X_test_strat, y_test_strat)\n",
    "    rows[name] = row\n",
    "    print(f\"[{name}] Best params: {search.best_params_}\")\n",
    "\n",
    "df_results = pd.DataFrame(rows.values()).sort_values(\"ROC-AUC\", ascending=False)\n",
    "print(\"\\n=== Model comparison (Optimized with class_weight) ===\")\n",
    "print(df_results.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1948c764",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_18776\\86359812.py:6: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.countplot(x='dropout_status', data=df, palette='Set2')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# 클래스 분포 카운트\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='dropout_status', data=df, palette='Set2')\n",
    "\n",
    "# 그래프에 비율 표시\n",
    "total = len(df)\n",
    "for p in plt.gca().patches:\n",
    "    count = p.get_height()\n",
    "    plt.gca().annotate(f'{count} ({count/total:.1%})', \n",
    "                       (p.get_x() + p.get_width() / 2., count),\n",
    "                       ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.title('Distribution of dropout_status')\n",
    "plt.xlabel('Dropout Status')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
